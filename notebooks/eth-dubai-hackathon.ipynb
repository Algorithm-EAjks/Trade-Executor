{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETHDubai hackathon \n",
    "\n",
    "This is an example notebook how to construct a momentum based portfolio construction strategy\n",
    "using [Trading Strategy framework](https://tradingstrategy.ai/docs/) and backtest it for DeFi tokens.\n",
    "\n",
    "This backtest uses alpha model approach where each trading pair has a signal\n",
    "and basede on the signal strenghts we construct new portfolio weightings \n",
    "for the upcoming week.\n",
    "\n",
    "Some highlights of this notebook:\n",
    "\n",
    "* **Not a realistic trading strategy, but more of an code example** - this may generate profits or loss but this is outside the scode of this example\n",
    "* Make sure you have studied some simpler backtesting examples first\n",
    "* The backtest has all its code within a single Jupyter notebook\n",
    "    - The backtest code and charts are self-contained in a single file\n",
    "    - The example code is easy to read\n",
    "* Runs a backtest for a momentum strategy\n",
    "    - Long only    \n",
    "    - Because the strategy is long only, it trades only in a bull market, defined by a moving average signal\n",
    "    - Automatically chooses tokens that enter and exit market at Sushi on Polygon\n",
    "    - Support pairs that trade against WMATIC and USDC (quote tokens)\n",
    "    - Check trading pair available liquidity before taking any positions - uses coarse (resampled) liquidity data for liquidity aware backtesting    \n",
    "    - Pick some top tokens for each strategy cycle\n",
    "    - Based on using a trading pair momentum as an alpha signal\n",
    "    - Uses take profit / stop loss to close the positions outside the rebalance cycle\n",
    "    - Ignores price impact, and thus may cause unrealistic results\n",
    "    - Ignores extra fees on a three leg trade of USDC->WMATIC->target asset when opening a position\n",
    "* Demostrates statistics and performance analyses\n",
    "    - Equity curve with comparison to buy and hold WMATIC\n",
    "    - Bull/bear market indicator when the strategy is trading\n",
    "    - Summary statistics of the strategy\n",
    "    - Summary statistics of individual pairs traded\n",
    "* You need a [Trading Strategy API key](https://tradingstrategy.ai/trading-view/backtesting) to run the notebook\n",
    "* The notebook will download more than 10GB data\n",
    "* You will need a powerful computer to run this notebook (> 16GB RAM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tradingstrategy.chain import ChainId\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.strategy.cycle import CycleDuration\n",
    "from tradeexecutor.strategy.strategy_module import StrategyType, TradeRouting, ReserveCurrency\n",
    "\n",
    "# Name of this strategy, will be used to show on charts\n",
    "strategy_name = \"ETHDubai hackathon strategy\"\n",
    "\n",
    "# Tell what trade execution engine version this strategy needs to use\n",
    "trading_strategy_engine_version = \"0.1\"\n",
    "\n",
    "# What kind of strategy we are running.\n",
    "# This tells we are going to use\n",
    "trading_strategy_type = StrategyType.managed_positions\n",
    "\n",
    "# How our trades are routed.\n",
    "trade_routing = TradeRouting.ignore\n",
    "\n",
    "# Which chain we are trading on\n",
    "chain_id = ChainId.polygon\n",
    "\n",
    "# Which exchange we are trading on\n",
    "exchange_slug = \"sushi\"\n",
    "\n",
    "# Which quote tokens we use\n",
    "quote_tokens = {\n",
    "    \"0x2791bca1f2de4661ed88a30c99a7a9449aa84174\",  # USDC\n",
    "    \"0x0d500b1d8e8ef31e21c99d1db9a6444d3adf1270\",  # WMATIC\n",
    "}\n",
    "\n",
    "# Set cycle to 7 days and look back the momentum of the previous candle\n",
    "trading_strategy_cycle = CycleDuration.cycle_4d\n",
    "momentum_lookback_period = datetime.timedelta(days=4)\n",
    "\n",
    "# Hold N top coins for every cycle\n",
    "max_assets_in_portfolio = 3\n",
    "\n",
    "# Leave 50% cash buffer\n",
    "value_allocated_to_positions = 0.5\n",
    "\n",
    "#\n",
    "# Set the take profit/stop loss for our postions.\n",
    "# Aim for asymmetric opportunities - upside is higher than downside\n",
    "#\n",
    "\n",
    "# Set % stop loss over mid price\n",
    "stop_loss = 0.97\n",
    "\n",
    "# Set % take profit over mid price\n",
    "take_profit = 1.33\n",
    "\n",
    "# The momentum period price must be up % for us to take a long position\n",
    "minimum_mometum_threshold = 0.03\n",
    "\n",
    "# The amount of XY liquidity a pair must have on DEX before \n",
    "# we are happy to take any position.\n",
    "minimum_liquidity_threshold = 300_000\n",
    "\n",
    "# Don't bother with trades that would move position\n",
    "# less than 300 USD\n",
    "minimum_rebalance_trade_threshold = 300\n",
    "\n",
    "# decide_trades() operates on 1d candles\n",
    "candle_data_time_frame = TimeBucket.d1\n",
    "\n",
    "# Use hourly candles to trigger the stop loss\n",
    "stop_loss_data_granularity = TimeBucket.h1\n",
    "\n",
    "# Strategy keeps its cash in USDC\n",
    "reserve_currency = ReserveCurrency.usdc\n",
    "\n",
    "# Define the periods when the native asset price is\n",
    "# above its simple moving average (SMA)\n",
    "bull_market_moving_average_window = pd.Timedelta(days=15)\n",
    "\n",
    "# The duration of the backtesting period\n",
    "start_at = datetime.datetime(2022, 1, 1)\n",
    "end_at = datetime.datetime(2023, 2, 1)\n",
    "\n",
    "# Start with 10,000 USD\n",
    "initial_deposit = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tradingstrategy.chain import ChainId\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.strategy.cycle import CycleDuration\n",
    "from tradeexecutor.strategy.strategy_module import StrategyType, TradeRouting, ReserveCurrency\n",
    "\n",
    "# Name of this strategy, will be used to show on charts\n",
    "strategy_name = \"ETHDubai hackathon strategy\"\n",
    "\n",
    "# Tell what trade execution engine version this strategy needs to use\n",
    "trading_strategy_engine_version = \"0.1\"\n",
    "\n",
    "# What kind of strategy we are running.\n",
    "# This tells we are going to use\n",
    "trading_strategy_type = StrategyType.managed_positions\n",
    "\n",
    "# How our trades are routed.\n",
    "trade_routing = TradeRouting.ignore\n",
    "\n",
    "# Which chain we are trading on\n",
    "chain_id = ChainId.polygon\n",
    "\n",
    "# Which exchange we are trading on\n",
    "exchange_slug = \"sushi\"\n",
    "\n",
    "# Which quote tokens we use\n",
    "quote_tokens = {\n",
    "    \"0x2791bca1f2de4661ed88a30c99a7a9449aa84174\",  # USDC\n",
    "    \"0x0d500b1d8e8ef31e21c99d1db9a6444d3adf1270\",  # WMATIC\n",
    "}\n",
    "\n",
    "# Set cycle to 7 days and look back the momentum of the previous candle\n",
    "trading_strategy_cycle = CycleDuration.cycle_4d\n",
    "momentum_lookback_period = datetime.timedelta(days=4)\n",
    "\n",
    "# Hold N top coins for every cycle\n",
    "max_assets_in_portfolio = 3\n",
    "\n",
    "# Leave 50% cash buffer\n",
    "value_allocated_to_positions = 0.5\n",
    "\n",
    "#\n",
    "# Set the take profit/stop loss for our postions.\n",
    "# Aim for asymmetric opportunities - upside is higher than downside\n",
    "#\n",
    "\n",
    "# Set % stop loss over mid price\n",
    "stop_loss = 0.97\n",
    "\n",
    "# Set % take profit over mid price\n",
    "take_profit = 1.33\n",
    "\n",
    "# The momentum period price must be up % for us to take a long position\n",
    "minimum_mometum_threshold = 0.03\n",
    "\n",
    "# The amount of XY liquidity a pair must have on DEX before \n",
    "# we are happy to take any position.\n",
    "minimum_liquidity_threshold = 300_000\n",
    "\n",
    "# Don't bother with trades that would move position\n",
    "# less than 300 USD\n",
    "minimum_rebalance_trade_threshold = 300\n",
    "\n",
    "# decide_trades() operates on 1d candles\n",
    "candle_data_time_frame = TimeBucket.d1\n",
    "\n",
    "# Use hourly candles to trigger the stop loss\n",
    "stop_loss_data_granularity = TimeBucket.h1\n",
    "\n",
    "# Strategy keeps its cash in USDC\n",
    "reserve_currency = ReserveCurrency.usdc\n",
    "\n",
    "# Define the periods when the native asset price is\n",
    "# above its simple moving average (SMA)\n",
    "bull_market_moving_average_window = pd.Timedelta(days=15)\n",
    "\n",
    "# The duration of the backtesting period\n",
    "start_at = datetime.datetime(2022, 1, 1)\n",
    "end_at = datetime.datetime(2023, 2, 1)\n",
    "\n",
    "# Start with 10,000 USD\n",
    "initial_deposit = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy logic and trade decisions\n",
    "\n",
    "`decide_trades` function decide what trades to take.\n",
    "In this example, we calculate two exponential moving averages\n",
    "(EMAs) and make decisions based on those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.state.visualisation import PlotKind\n",
    "from tradeexecutor.strategy.trading_strategy_universe import translate_trading_pair\n",
    "from typing import List, Dict\n",
    "\n",
    "from pandas_ta.overlap import sma\n",
    "\n",
    "from tradingstrategy.universe import Universe\n",
    "from tradeexecutor.strategy.weighting import weight_by_1_slash_n\n",
    "from tradeexecutor.strategy.alpha_model import AlphaModel\n",
    "from tradeexecutor.state.trade import TradeExecution\n",
    "from tradeexecutor.strategy.pricing_model import PricingModel\n",
    "from tradeexecutor.strategy.pandas_trader.position_manager import PositionManager\n",
    "from tradeexecutor.state.state import State\n",
    "\n",
    "\n",
    "def decide_trades(\n",
    "    timestamp: pd.Timestamp,\n",
    "    universe: Universe,\n",
    "    state: State,\n",
    "    pricing_model: PricingModel,\n",
    "    cycle_debug_data: Dict\n",
    ") -> List[TradeExecution]:\n",
    "\n",
    "    # Create a position manager helper class that allows us easily to create\n",
    "    # opening/closing trades for different positions\n",
    "    position_manager = PositionManager(timestamp, universe, state, pricing_model)\n",
    "\n",
    "    alpha_model = AlphaModel(timestamp)\n",
    "\n",
    "    # Watch out for the inclusive range and include and avoid peeking in the future\n",
    "    adjusted_timestamp = timestamp - pd.Timedelta(seconds=1)\n",
    "    start = adjusted_timestamp - momentum_lookback_period - datetime.timedelta(seconds=1)\n",
    "    end = adjusted_timestamp \n",
    "\n",
    "    candle_universe = universe.candles\n",
    "    pair_universe = universe.pairs\n",
    "\n",
    "    # First figure out are we in a bear or a bull market condition.\n",
    "    # Our rule for a bull market is that the price of the native token of the blockchain\n",
    "    # is above its simple moving average.\n",
    "    # Please see the notebook commments why we define this condition like this.\n",
    "    bullish = False\n",
    "\n",
    "    # Plot the WMATIC simple moving average.\n",
    "    matic_usdc = pair_universe.get_pair(\n",
    "        chain_id,\n",
    "        exchange_slug,\n",
    "        \"WMATIC\",\n",
    "        \"USDC\"\n",
    "    )\n",
    "\n",
    "    matic_usdc_candles = candle_universe.get_last_entries_by_pair_and_timestamp(matic_usdc.pair_id, timestamp)\n",
    "\n",
    "    if len(matic_usdc_candles) > 0:\n",
    "        matic_close = matic_usdc_candles[\"close\"]\n",
    "        matic_price_now = matic_close.iloc[-1]\n",
    "\n",
    "        # Count how many candles worth of data needed\n",
    "        matic_sma = sma(matic_close, length=bull_market_moving_average_window / candle_data_time_frame.to_timedelta())\n",
    "        if matic_sma is not None:\n",
    "            # SMA cannot be forward filled at the beginning of the backtest period\n",
    "            sma_now = matic_sma[-1]\n",
    "            assert sma_now > 0, f\"SMA was zero for {timestamp}, probably issue with the data?\"\n",
    "            state.visualisation.plot_indicator(\n",
    "                timestamp,\n",
    "                \"Native token SMA\",\n",
    "                PlotKind.technical_indicator_on_price,\n",
    "                sma_now,\n",
    "            )\n",
    "\n",
    "            if matic_price_now > sma_now:\n",
    "                bullish = True\n",
    "\n",
    "        # Get candle data for all candles, inclusive time range\n",
    "    candle_data = candle_universe.iterate_samples_by_pair_range(start, end)\n",
    "\n",
    "    # Because this is long only strategy, we will honour our momentum signals only in a bull market\n",
    "    if bullish:\n",
    "\n",
    "        # Iterate over all candles for all pairs in this timestamp (ts)\n",
    "        for pair_id, pair_df in candle_data:\n",
    "\n",
    "            last_candle = pair_df.iloc[-1]\n",
    "\n",
    "            assert last_candle[\"timestamp\"] < timestamp, \"Something wrong with the data - we should not be able to peek the candle of the current timestamp, but always use the previous candle\"\n",
    "\n",
    "            open = last_candle[\"open\"]\n",
    "            close = last_candle[\"close\"]\n",
    "\n",
    "            # Get the pair information and translate it to a serialisable strategy object\n",
    "            dex_pair = pair_universe.get_pair_by_id(pair_id)\n",
    "            pair = translate_trading_pair(dex_pair)\n",
    "\n",
    "            available_liquidity = universe.resampled_liquidity.get_liquidity_fast(pair_id, adjusted_timestamp)\n",
    "            if available_liquidity < minimum_liquidity_threshold:\n",
    "                # Too limited liquidity, skip this pair\n",
    "                continue\n",
    "\n",
    "            # We define momentum as how many % the trading pair price gained during\n",
    "            # the momentum window\n",
    "            momentum = (close - open) / open\n",
    "\n",
    "            # This pair has not positive momentum,\n",
    "            # we only buy when stuff goes up\n",
    "            if momentum <= minimum_mometum_threshold:\n",
    "                continue\n",
    "\n",
    "            alpha_model.set_signal(\n",
    "                pair,\n",
    "                momentum,\n",
    "                stop_loss=stop_loss,\n",
    "                take_profit=take_profit,\n",
    "            )\n",
    "\n",
    "    # Select max_assets_in_portfolio assets in which we are going to invest\n",
    "    # Calculate a weight for ecah asset in the portfolio using 1/N method based on the raw signal\n",
    "    alpha_model.select_top_signals(max_assets_in_portfolio)\n",
    "    alpha_model.assign_weights(method=weight_by_1_slash_n)\n",
    "    alpha_model.normalise_weights()\n",
    "\n",
    "    # Load in old weight for each trading pair signal,\n",
    "    # so we can calculate the adjustment trade size\n",
    "    alpha_model.update_old_weights(state.portfolio)\n",
    "\n",
    "    # Calculate how much dollar value we want each individual position to be on this strategy cycle,\n",
    "    # based on our total available equity\n",
    "    portfolio = position_manager.get_current_portfolio()\n",
    "    portfolio_target_value = portfolio.get_total_equity() * value_allocated_to_positions\n",
    "    alpha_model.calculate_target_positions(portfolio_target_value)\n",
    "\n",
    "    # Shift portfolio from current positions to target positions\n",
    "    # determined by the alpha signals (momentum)\n",
    "    trades = alpha_model.generate_rebalance_trades_and_triggers(\n",
    "        position_manager,\n",
    "        min_trade_threshold=minimum_rebalance_trade_threshold,  # Don't bother with trades under 300 USD\n",
    "    )\n",
    "\n",
    "    # Record alpha model state so we can later visualise our alpha model thinking better\n",
    "    state.visualisation.add_calculations(timestamp, alpha_model.to_dict())\n",
    "\n",
    "    return trades\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the market data client\n",
    "\n",
    "The [Trading Strategy market data client](https://tradingstrategy.ai/docs/programming/api/client/index.html)\n",
    "is the Python library responsible for managing the data feeds needed to run the backtest.None\n",
    "\n",
    "We set up the market data client with an API key.\n",
    "\n",
    "[If you do not have an API key yet, you can register one](https://tradingstrategy.ai/trading-view/backtesting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Trading Strategy in Jupyter notebook environment, configuration is stored in /Users/alexurbs/.tradingstrategy\n"
     ]
    }
   ],
   "source": [
    "from tradingstrategy.client import Client\n",
    "\n",
    "client = Client.create_jupyter_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup trading universe\n",
    "\n",
    "We setup the trading universe for the backtesting.\n",
    "\n",
    "- Read in a handwritten allowed trading pair universe list\n",
    "\n",
    "- Download candle data\n",
    "\n",
    "- Print out trading pair addresses and volumes as the sanity check the pair defintions look correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a511a31388b45eebd6f3e05eb87bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading exchange dataset(Unknown total file size): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e111786ea919472cad3bcdb0820ab47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading trading pair dataset:   0%|          | 0/20390899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96b94b2f73e4a659b6c84f93c027c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading OHLCV data for 1d time bucket:   0%|          | 0/655342826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ef8a5bde72424698de50b2dfbbffe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading liquidity data for 1d time bucket:   0%|          | 0/530024487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b58a7428dc459588c6ea8274794fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading OHLCV data for 1h time bucket:   0%|          | 0/4780283236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     43\u001b[0m     universe \u001b[39m=\u001b[39m TradingStrategyUniverse\u001b[39m.\u001b[39mcreate_multipair_universe(\n\u001b[1;32m     44\u001b[0m         dataset,\n\u001b[1;32m     45\u001b[0m         [chain_id],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m         liquidity_resample_frequency\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1D\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m universe\n\u001b[0;32m---> 55\u001b[0m universe \u001b[39m=\u001b[39m create_trading_universe(\n\u001b[1;32m     56\u001b[0m     datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mutcnow(),\n\u001b[1;32m     57\u001b[0m     client,\n\u001b[1;32m     58\u001b[0m     ExecutionContext(mode\u001b[39m=\u001b[39;49mExecutionMode\u001b[39m.\u001b[39;49mbacktesting),\n\u001b[1;32m     59\u001b[0m     UniverseOptions(),\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe trading univers has \u001b[39m\u001b[39m{\u001b[39;00muniverse\u001b[39m.\u001b[39mget_pair_count()\u001b[39m}\u001b[39;00m\u001b[39m trading pairs\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mcreate_trading_universe\u001b[0;34m(ts, client, execution_context, universe_options)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m execution_context\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mis_live_trading(), \\\n\u001b[1;32m     19\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOnly strategy backtesting supported, got \u001b[39m\u001b[39m{\u001b[39;00mexecution_context\u001b[39m.\u001b[39mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Load data for our trading pair whitelist\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m dataset \u001b[39m=\u001b[39m load_all_data(\n\u001b[1;32m     23\u001b[0m     client,\n\u001b[1;32m     24\u001b[0m     time_frame\u001b[39m=\u001b[39;49mcandle_data_time_frame,\n\u001b[1;32m     25\u001b[0m     execution_context\u001b[39m=\u001b[39;49mexecution_context,\n\u001b[1;32m     26\u001b[0m     universe_options\u001b[39m=\u001b[39;49muniverse_options,\n\u001b[1;32m     27\u001b[0m     liquidity_time_frame\u001b[39m=\u001b[39;49mTimeBucket\u001b[39m.\u001b[39;49md1,\n\u001b[1;32m     28\u001b[0m     stop_loss_time_frame\u001b[39m=\u001b[39;49mstop_loss_data_granularity,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[39m# adapt Sushi routing params from Quickswap\u001b[39;00m\n\u001b[1;32m     32\u001b[0m routing_parameters \u001b[39m=\u001b[39m get_quickswap_default_routing_parameters(reserve_currency)\n",
      "File \u001b[0;32m~/trading-strategy-ai/trade-executor/tradeexecutor/strategy/trading_strategy_universe.py:1068\u001b[0m, in \u001b[0;36mload_all_data\u001b[0;34m(client, time_frame, execution_context, universe_options, with_liquidity, liquidity_time_frame, stop_loss_time_frame)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     liquidity \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m stop_loss_time_frame:\n\u001b[0;32m-> 1068\u001b[0m     stop_loss_candles \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mfetch_all_candles(stop_loss_time_frame)\u001b[39m.\u001b[39mto_pandas()\n\u001b[1;32m   1069\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1070\u001b[0m     stop_loss_candles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tradingstrategy/client.py:78\u001b[0m, in \u001b[0;36m_retry_corrupted_parquet_fetch.<locals>.impl\u001b[0;34m(self, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mwhile\u001b[39;00m attempts \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     77\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49mmethod_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmethod_kwargs)\n\u001b[1;32m     79\u001b[0m     \u001b[39m# TODO: Build expection list over the time by\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39m# observing issues in production\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, BrokenData) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m         \u001b[39m# This happens when we download Parquet file, but it is missing half\u001b[39;00m\n\u001b[1;32m     83\u001b[0m         \u001b[39m# e.g. due to interrupted download\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tradingstrategy/client.py:195\u001b[0m, in \u001b[0;36mClient.fetch_all_candles\u001b[0;34m(self, bucket)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m@_retry_corrupted_parquet_fetch\u001b[39m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch_all_candles\u001b[39m(\u001b[39mself\u001b[39m, bucket: TimeBucket) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pyarrow\u001b[39m.\u001b[39mTable:\n\u001b[1;32m    184\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get cached blob of candle data of a certain candle width.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[39m    The returned data can be between several hundreds of megabytes to several gigabytes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m    If the download seems to be corrupted, it will be attempted 3 times.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mfetch_candles_all_time(bucket)\n\u001b[1;32m    196\u001b[0m     \u001b[39mreturn\u001b[39;00m read_parquet(path)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tradingstrategy/transport/cache.py:286\u001b[0m, in \u001b[0;36mCachedHTTPTransport.fetch_candles_all_time\u001b[0;34m(self, bucket)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m# Download save the file\u001b[39;00m\n\u001b[1;32m    285\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_cached_file_path(fname)\n\u001b[0;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_response(path, \u001b[39m\"\u001b[39;49m\u001b[39mcandles-all\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mbucket\u001b[39;49m\u001b[39m\"\u001b[39;49m: bucket\u001b[39m.\u001b[39;49mvalue}, human_readable_hint\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading OHLCV data for \u001b[39;49m\u001b[39m{\u001b[39;49;00mbucket\u001b[39m.\u001b[39;49mvalue\u001b[39m}\u001b[39;49;00m\u001b[39m time bucket\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_cached_item(path)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tradingstrategy/transport/cache.py:240\u001b[0m, in \u001b[0;36mCachedHTTPTransport.save_response\u001b[0;34m(self, fpath, api_path, params, human_readable_hint)\u001b[0m\n\u001b[1;32m    238\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mSaving \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, fpath)\n\u001b[1;32m    239\u001b[0m \u001b[39m# https://stackoverflow.com/a/14114741/315168\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequests, fpath, url, params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, human_readable_hint)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tradingstrategy/environment/jupyter.py:127\u001b[0m, in \u001b[0;36mdownload_with_tqdm_progress_bar\u001b[0;34m(session, path, url, params, timeout, human_readable_hint)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mwith\u001b[39;00m tqdm\u001b[39m.\u001b[39mwrapattr(r\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39mfile_size, desc\u001b[39m=\u001b[39mdesc) \u001b[39mas\u001b[39;00m r_raw:\n\u001b[1;32m    126\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 127\u001b[0m         shutil\u001b[39m.\u001b[39;49mcopyfileobj(r_raw, f)\n\u001b[1;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/shutil.py:195\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    193\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[1;32m    194\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    197\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/tqdm/utils.py:193\u001b[0m, in \u001b[0;36mCallbackIOWrapper.__init__.<locals>.read\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 193\u001b[0m     data \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    194\u001b[0m     callback(\u001b[39mlen\u001b[39m(data))\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-zDrfc5oV-py3.10/lib/python3.10/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tradingstrategy.client import Client\n",
    "\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse, load_all_data\n",
    "from tradeexecutor.strategy.trading_strategy_universe import load_partial_data\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext\n",
    "from tradeexecutor.strategy.execution_context import ExecutionMode\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "from tradeexecutor.ethereum.routing_data import get_quickswap_default_routing_parameters\n",
    "\n",
    "\n",
    "def create_trading_universe(\n",
    "    ts: datetime.datetime,\n",
    "    client: Client,\n",
    "    execution_context: ExecutionContext,\n",
    "    universe_options: UniverseOptions,\n",
    ") -> TradingStrategyUniverse:\n",
    "\n",
    "    assert not execution_context.mode.is_live_trading(), \\\n",
    "        f\"Only strategy backtesting supported, got {execution_context.mode}\"\n",
    "\n",
    "    # Load data for our trading pair whitelist\n",
    "    dataset = load_all_data(\n",
    "        client,\n",
    "        time_frame=candle_data_time_frame,\n",
    "        execution_context=execution_context,\n",
    "        universe_options=universe_options,\n",
    "        liquidity_time_frame=TimeBucket.d1,\n",
    "        stop_loss_time_frame=stop_loss_data_granularity,\n",
    "    )\n",
    "\n",
    "    # adapt Sushi routing params from Quickswap\n",
    "    routing_parameters = get_quickswap_default_routing_parameters(reserve_currency)\n",
    "\n",
    "    # factory -> (router, init_code_hash)\n",
    "    # init code hash: https://polygonscan.com/address/0x1b02dA8Cb0d097eB8D57A175b88c7D8b47997506#code#L103\n",
    "    routing_parameters[\"factory_router_map\"] = {\n",
    "        \"0xc35DADB65012eC5796536bD9864eD8773aBc74C4\": (\n",
    "            \"0x1b02dA8Cb0d097eB8D57A175b88c7D8b47997506\",\n",
    "            \"0xe18a34eb0e04b04f7a0ac29a6e80748dca96319b42c54d679cb821dca90c6303\",\n",
    "        )\n",
    "    }\n",
    "\n",
    "    universe = TradingStrategyUniverse.create_multipair_universe(\n",
    "        dataset,\n",
    "        [chain_id],\n",
    "        [exchange_slug],\n",
    "        quote_tokens=quote_tokens,\n",
    "        reserve_token=routing_parameters[\"reserve_token_address\"],\n",
    "        factory_router_map=routing_parameters[\"factory_router_map\"],\n",
    "        liquidity_resample_frequency=\"1D\",\n",
    "    )\n",
    "\n",
    "    return universe\n",
    "\n",
    "universe = create_trading_universe(\n",
    "    datetime.datetime.utcnow(),\n",
    "    client,\n",
    "    ExecutionContext(mode=ExecutionMode.backtesting),\n",
    "    UniverseOptions(),\n",
    ")\n",
    "\n",
    "print(f\"The trading univers has {universe.get_pair_count()} trading pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run backtest\n",
    "\n",
    "Run backtest using giving trading universe and strategy function.\n",
    "\n",
    "- Running the backtest outputs `state` object that contains all the information\n",
    "on the backtesting position and trades.\n",
    "- The trade execution engine will download the necessary datasets to run the backtest.\n",
    "  The datasets may be large, several gigabytes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tradeexecutor.backtest.backtest_runner import run_backtest_inline\n",
    "\n",
    "state, universe, debug_dump = run_backtest_inline(\n",
    "    name=strategy_name,\n",
    "    start_at=start_at,\n",
    "    end_at=end_at,\n",
    "    client=client,\n",
    "    cycle_duration=trading_strategy_cycle,\n",
    "    decide_trades=decide_trades,\n",
    "    create_trading_universe=create_trading_universe,\n",
    "    initial_deposit=initial_deposit,\n",
    "    reserve_currency=reserve_currency,\n",
    "    trade_routing=trade_routing,\n",
    "    log_level=logging.WARNING,\n",
    "    universe=universe,\n",
    "    data_delay_tolerance=pd.Timedelta(\"7d\"),\n",
    ")\n",
    "\n",
    "trade_count = len(list(state.portfolio.get_all_trades()))\n",
    "print(f\"Backtesting completed, backtested strategy made {trade_count} trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine backtest results\n",
    "\n",
    "Examine `state` that contains \n",
    "- All actions the trade executor took\n",
    "- Visualisation and diagnostics data associated with the actity\n",
    "\n",
    "We plot out a chart that shows\n",
    "- The price action\n",
    "- When the strategy made buys or sells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Positions taken: {len(list(state.portfolio.get_all_positions()))}\")\n",
    "print(f\"Trades made: {len(list(state.portfolio.get_all_trades()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking the strategy performance\n",
    "\n",
    "Here we benchmark the strategy performance against some baseline scenarios.\n",
    "\n",
    "- Buy and hold MATIC\n",
    "- Buy and hold US Dollar (do nothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.visual.benchmark import visualise_benchmark\n",
    "\n",
    "matic_usdc = universe.get_pair_by_human_description((chain_id, exchange_slug, \"WMATIC\", \"USDC\"))\n",
    "matic_usdc_candles = universe.universe.candles.get_candles_by_pair(matic_usdc.internal_id)\n",
    "\n",
    "fig = visualise_benchmark(\n",
    "    state.name,\n",
    "    portfolio_statistics=state.stats.portfolio,\n",
    "    all_cash=state.portfolio.get_initial_deposit(),\n",
    "    buy_and_hold_asset_name=\"WMATIC\",\n",
    "    buy_and_hold_price_series=matic_usdc_candles[\"close\"],\n",
    "    start_at=start_at,\n",
    "    end_at=end_at\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bull/bear market moving average analysis\n",
    "\n",
    "We do not want to trade using a long only strategy in a \"bear market\" when all assets are dropping, \n",
    "as slow moving momentum strategy won't be able to catch good pumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from tradeexecutor.visual.technical_indicator import export_plot_as_dataframe\n",
    "\n",
    "# Set up DataFrames where one has price and one has moving average\n",
    "candles = matic_usdc_candles  # OHLCV data\n",
    "sma_plot = state.visualisation.plots[\"Native token SMA\"]\n",
    "sma_df = export_plot_as_dataframe(sma_plot)  # Simple moving average values\n",
    "\n",
    "# Create a DataFrame that contains values from all of our plots using the same master DateTimeIndex.\n",
    "# Namely moving averages have less samples, because moving average cannot be calculated\n",
    "# early on as the time window has not yet enough data.\n",
    "# We will also interpolate indicator values, as our indicator has less granular\n",
    "# DateTimeIndex as the price data.\n",
    "indicator_df = pd.DataFrame(index=candles.index)\n",
    "indicator_df[\"price\"] = candles[\"close\"]\n",
    "indicator_df[\"indicator_value\"] = sma_df[\"value\"]\n",
    "indicator_df[\"indicator_value\"].interpolate(inplace=True)\n",
    "\n",
    "# There is a multiyear bug in Plotly that you cannot use connectgaps and fill in the same plot.\n",
    "# This is why we set the indicator value to the price value when we do not want to plot the area,\n",
    "# as this will fill area with the size of 0\n",
    "# https://github.com/plotly/plotly.js/issues/1132#issuecomment-531030346\n",
    "indicator_df[\"green_above\"] = indicator_df.apply(lambda row: row[\"indicator_value\"] if row[\"price\"] > row[\"indicator_value\"] else row[\"price\"], axis=\"columns\")\n",
    "indicator_df[\"red_below\"] = indicator_df.apply(lambda row: row[\"indicator_value\"] if row[\"price\"] <= row[\"indicator_value\"] else row[\"price\"], axis=\"columns\")\n",
    "\n",
    "# Fill the area between close price and SMA indicator\n",
    "# See https://plotly.com/python/filled-area-plots/#interior-filling-for-area-chart\n",
    "# See also https://stackoverflow.com/a/64743166/315168\n",
    "fig = go.Figure(\n",
    "    layout={\n",
    "        \"title\": \"Bull/bear market indicator\",\n",
    "        \"height\": 800,\n",
    "    }\n",
    ")\n",
    "\n",
    "# We need to use an invisible trace so we can reset \"next y\"\n",
    "# for the red area indicator\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indicator_df.index,\n",
    "        y=indicator_df[\"price\"],\n",
    "        line_color=\"rgba(0,0,0,0)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot out the\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indicator_df.index,\n",
    "        y=indicator_df[\"green_above\"],\n",
    "        name=\"Price above SMA (bull market)\",\n",
    "        line_color=\"green\",\n",
    "        connectgaps=False,\n",
    "        fillcolor=\"green\",\n",
    "        fill='tonexty',\n",
    "    )\n",
    ")\n",
    "\n",
    "# We need to use an invisible trace so we can reset \"next y\"\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indicator_df.index,\n",
    "        y=indicator_df[\"price\"],\n",
    "        line_color=\"rgba(0,0,0,0)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indicator_df.index,\n",
    "        y=indicator_df[\"red_below\"],\n",
    "        name=\"Price below SMA (bear market)\",\n",
    "        line_color=\"red\",\n",
    "        connectgaps=False,\n",
    "        fillcolor=\"red\",\n",
    "        fill='tonexty',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indicator_df.index,\n",
    "        y=indicator_df[\"price\"],\n",
    "        name=f\"Native token price\",\n",
    "        line_color=\"black\",\n",
    "    )\n",
    ")\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the strategy success\n",
    "\n",
    "Here we calculate statistics on how well the strategy performed.\n",
    "\n",
    "- Won/lost trades\n",
    "- Timeline of taken positions with color coding of trade performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.trade_analyser import build_trade_analysis\n",
    "\n",
    "analysis = build_trade_analysis(state.portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy summary\n",
    "\n",
    "Overview of strategy performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import display\n",
    "\n",
    "summary = analysis.calculate_summary_statistics()\n",
    "\n",
    "with pd.option_context(\"display.max_row\", None):\n",
    "    display(summary.to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading pair analysis\n",
    "\n",
    "Show the summary of the strategy trades for each different trading pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.multipair import analyse_multipair\n",
    "from tradeexecutor.analysis.multipair import forma_multipair_summary\n",
    "\n",
    "multipair_summary = analyse_multipair(state)\n",
    "display(forma_multipair_summary(multipair_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha model timeline\n",
    "\n",
    "**We do not display individual timeline of the positions due to large number of pairs involved**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual pair analysis\n",
    "\n",
    "Examine one trading pair and how it performed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.visual.single_pair import visualise_single_pair_positions_with_duration_and_slippage\n",
    "\n",
    "target_pair = universe.universe.pairs.get_pair(\n",
    "    chain_id,\n",
    "    exchange_slug,\n",
    "    \"IXT\",\n",
    "    \"WMATIC\"\n",
    ")\n",
    "\n",
    "ticker = target_pair.get_ticker()\n",
    "pair_candles = universe.backtest_stop_loss_candles.get_candles_by_pair(target_pair.pair_id)\n",
    "\n",
    "fig = visualise_single_pair_positions_with_duration_and_slippage(\n",
    "    state,\n",
    "    pair_id=target_pair.pair_id,\n",
    "    title=f\"{ticker} entries and exits\",\n",
    "    candles=pair_candles,\n",
    "    start_at=start_at,\n",
    "    end_at=end_at,\n",
    "    technical_indicators=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing notes\n",
    "\n",
    "Print out a line to signal the notebook finished the execution successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('trade-executor-zDrfc5oV-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f45fb66dacef78c495ceec56f258b06b84bd9cb2c0a9a6d3656125fb3c018996"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
