{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore signal/price movement relationship\n",
    "\n",
    "This is an example notebook to explore whether a trading signal results to profitable trades.\n",
    "\n",
    "- 3 days \n",
    "- It explores a small set of pairs on Uni v3 on Polygon\n",
    "- Both long and short are considered (though shorts might be theoretical only, if such a lending market doest not exist in the point of time)\n",
    "\n",
    "First run to prepare the dataset:\n",
    "\n",
    "```shell\n",
    "python scripts/prepare-polygon-momentum-candles.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tradingstrategy.client import Client\n",
    "from tradingstrategy.chain import ChainId\n",
    "from tradingstrategy.pair import PandasPairUniverse\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.utils.default_strategies import get_default_strategies_path\n",
    "from tradeexecutor.strategy.execution_context import notebook_execution_context\n",
    "from tradeexecutor.utils.default_strategies import get_default_strategies_path\n",
    "from tradeexecutor.strategy.strategy_module import read_strategy_module\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse, load_partial_data, load_trading_and_lending_data\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "\n",
    "client = Client.create_jupyter_client()\n",
    "\n",
    "# Load preprocessed candle dataset\n",
    "# See fetch-binance-candles.py   \n",
    "time_bucket = TimeBucket.h1\n",
    "fpath = f\"/tmp/binance-candles-{time_bucket.value}.parquet\"\n",
    "all_candles_df = pd.read_parquet(fpath)\n",
    "\n",
    "interesting_pairs = {\n",
    "     \"ETHUSDT\",\n",
    "     \"BTCUSDT\",\n",
    "     \"LINKUSDT\",\n",
    "     \"MATICUSDT\",\n",
    "     \"AAVEUSDT\",\n",
    "     \"COMPUSDT\",\n",
    "     \"MKRUSDT\",\n",
    "     \"BNBUSDT\",\n",
    "     \"AVAXUSDT\",\n",
    "     \"CAKEUSDT\",\n",
    "     \"SNXUSDT\",\n",
    "     \"CRVUSDT\",\n",
    "}\n",
    "\n",
    "#all_candles_df = all_candles_df[all_candles_df[\"pair_id\"].isin(interesting_pairs)]\n",
    "pair_ids = all_candles_df[\"pair_id\"].unique()\n",
    "\n",
    "print(f\"We are looking {len(pair_ids)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive viewer mode\n",
    "\n",
    "Set Plotly chart output mode to interactive viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.utils.notebook import OutputMode, setup_charting_and_output\n",
    "\n",
    "# setup_charting_and_output(OutputMode.interactive, max_rows=35, height=1000)\n",
    "setup_charting_and_output(\n",
    "    OutputMode.static, \n",
    "    image_format=\"png\",\n",
    "    width=1500,\n",
    "    height=1200,\n",
    "    max_rows=30,    \n",
    "    #min_rows=10,\n",
    ")\n",
    "\n",
    "#pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter trading pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingstrategy.pair import filter_for_stablecoins, StablecoinFilteringMode\n",
    "\n",
    "candles_df = all_candles_df\n",
    "\n",
    "print(f\"We have {len(pair_ids)} tradeable pairs\")\n",
    "print(f\"We have {len(candles_df):,} candles for tradeable pairs, out of {len(all_candles_df):,} total candles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore signal vs price change\n",
    "\n",
    "Create a function `calculate_signal_vs_profit` which calculates \n",
    "- Signal (naive momentum)\n",
    "- Profit: the last and the best future price we can get\n",
    "- Allows us to play around with different time windows\n",
    "- Split between shorts and longs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.frequencies import to_offset\n",
    "import humanize\n",
    "\n",
    "# Set up parameters of time windows\n",
    "# we use for this notebook run\n",
    "#lookback_window = pd.Timedelta(days=2)\n",
    "#profit_window = pd.Timedelta(days=2)\n",
    "\n",
    "lookback_window = pd.Timedelta(hours=4)\n",
    "profit_window = pd.Timedelta(hours=4)\n",
    "\n",
    "long_lookback_window = lookback_window * 4\n",
    "daily_volume_threshold = 10_000\n",
    "\n",
    "# short - long EMA pairs\n",
    "short_long_ema_pairs = [\n",
    "    (2, 4),\n",
    "    # (16, 48),\n",
    "    # (32, 96),\n",
    "]\n",
    "\n",
    "# Normalise EMA diff to 90 days/90 hours\n",
    "ema_diff_short_normalisation_period = 24*7\n",
    "ema_diff_long_normalisation_period =  30*24\n",
    "\n",
    "min_entries = 14\n",
    "\n",
    "min_age = pd.DateOffset(days=20)\n",
    "\n",
    "zero_signal_cut_off = 0.0001\n",
    "\n",
    "quantile_sanity_threshold = 0.9995\n",
    "\n",
    "#signal_source = \"momentum\"\n",
    "signal_source = \"weighted_ema\"\n",
    "\n",
    "apply_filter_by_signal = False\n",
    "apply_filter_by_profit = False\n",
    "apply_response_function = False\n",
    "\n",
    "# Use later in chart titles\n",
    "signal_window_label = humanize.naturaldelta(lookback_window)\n",
    "profit_window_label = humanize.naturaldelta(profit_window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `calculate_signal_vs_price_for_pair` which calculates \n",
    "- Calculates the signal vs. for certain trading pair\n",
    "- Bundle few different pairs to the same `DataFrame` so we can examine them together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e, sqrt\n",
    "import numpy as np\n",
    "from pandas.core.groupby import DataFrameGroupBy\n",
    "from pandas_ta import ema, pvt, obv\n",
    "\n",
    "\n",
    "def calculate_ema_signal(df: pd.DataFrame):\n",
    "    \"\"\"Calculate different EMA, their diffs as a single signal\n",
    "\n",
    "    The signal is based on the idea that when short moving average or price\n",
    "    is moving faster than the long moving average of the price,\n",
    "    the asset has momentu.\n",
    "\n",
    "    - We calculate three different long EMA and short EMA differences\n",
    "    - We normalise these difference over the price development of some duration\n",
    "    - Each normalised difference is mapped to -1 ... 1\n",
    "    - Signal is equally weighted sum of all SMA diffs\n",
    "\n",
    "    Sources:\n",
    "\n",
    "    - Momentum and trend following trading strategies for currencies and bitcoin\n",
    "      by Janick Rohrbach, Silvan Suremann, Joerg Osterriede]\n",
    "\n",
    "    - Dissecting Investment Strategies in the Cross Section and Time Series\n",
    "      by Jamil Baza, Nick Grangerb, Campbell R. Harveyc, Nicolas Le Rouxd and Sandy Rattraye\n",
    "\n",
    "    :return:\n",
    "        DataFrame with added columns.\n",
    "\n",
    "        Columns: signal, ema_signal_1, ema_long_1, ema_short_1, ema_diff_1...\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Did we manage to calculate all long/short EMA pairs for this pair\n",
    "    # or is the data duration too short / not enough data\n",
    "    enough_data = True\n",
    "\n",
    "    for idx, ema_tuple in enumerate(short_long_ema_pairs, start=1):\n",
    "        short_ema, long_ema = ema_tuple\n",
    "        assert short_ema < long_ema\n",
    "        df[f\"ema_long_{idx}\"] = ema(df[\"close\"], length=long_ema) \n",
    "        df[f\"ema_short_{idx}\"] = ema(df[\"close\"], length=short_ema)\n",
    "        df[f\"ema_diff_{idx}\"] = df[f\"ema_short_{idx}\"] - df[f\"ema_long_{idx}\"]\n",
    "\n",
    "        # Normalise EMA diff with 90 candles moving standard deviation        \n",
    "        df[f\"ema_diff_normalised_{idx}\"] = df[f\"ema_diff_{idx}\"] / df[f\"ema_diff_{idx}\"].rolling(ema_diff_short_normalisation_period).std()\n",
    "        # Normalise the normalised EMA diff with 280 candles moving standard deviation\n",
    "        df[f\"ema_diff_double_normalised_{idx}\"] = df[f\"ema_diff_normalised_{idx}\"] / df[f\"ema_diff_normalised_{idx}\"].rolling(ema_diff_long_normalisation_period).std()\n",
    "\n",
    "        # Apply response function to normalise signal on -1 ... +1 range\n",
    "        if apply_response_function:\n",
    "            # df[f\"ema_diff_double_normalised_{idx}\"] = df[f\"ema_diff_normalised_{idx}\"]\n",
    "            # x exp(-x^2 / 4)\n",
    "            # 0.858\n",
    "            x = df[f\"ema_diff_double_normalised_{idx}\"]\n",
    "            denominator = sqrt(2) * e**(-0.5)\n",
    "            exponent = (x**2) / -4\n",
    "\n",
    "            if not pd.isnull(exponent).all():\n",
    "                exponented = np.exp(exponent)\n",
    "                ranged_response = df[f\"ema_signal_{idx}\"] = df[f\"ema_diff_double_normalised_{idx}\"] * exponented / denominator\n",
    "            else:\n",
    "                # Could not calculate any of the exponents because all values in the series are NaN\n",
    "                enough_data = False\n",
    "                break\n",
    "\n",
    "            assert ranged_response.max() < 1.1\n",
    "            assert ranged_response.min() > -1.1\n",
    "\n",
    "        else:\n",
    "            # Pass normalised EMA diff as is\n",
    "            # df[f\"ema_signal_{idx}\"] = df[f\"ema_diff_double_normalised_{idx}\"]\n",
    "            df[f\"ema_signal_{idx}\"] = df[f\"ema_diff_normalised_{idx}\"]\n",
    "\n",
    "    if enough_data:\n",
    "        df[\"signal\"] = 0\n",
    "        # We could calculate partial results for all EMA pairs        \n",
    "        for idx, ema_tuple in enumerate(short_long_ema_pairs, start=1):\n",
    "            df[\"signal\"] += df[f\"ema_signal_{idx}\"] \n",
    "        df[\"signal\"] = df[\"signal\"] / len(short_long_ema_pairs)\n",
    "    else:\n",
    "        df[\"signal\"] = pd.NA\n",
    "\n",
    "    # Trading day needs to use signal calculated from the previous day's data\n",
    "    df[\"signal\"] = df[\"signal\"].shift(1)\n",
    "\n",
    "    return df    \n",
    "\n",
    "\n",
    "def calculate_signal_vs_profit(\n",
    "    df: pd.DataFrame, \n",
    "    pair_id: str,\n",
    "    momentum_window: pd.Timedelta, \n",
    "    profit_window: pd.Timedelta,\n",
    "    time_frame: pd.Timedelta,        \n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate signals and profits for all incoming candles.\"\"\"\n",
    "\n",
    "    number_of_look_back_candles = lookback_window / time_frame\n",
    "    number_of_look_forward_candles = profit_window / time_frame\n",
    "    assert number_of_look_forward_candles > 0 and number_of_look_forward_candles.is_integer(), f\"Could not calculate candle count that fits into profit window {profit_window} for data time frame {time_frame}\"\n",
    "    assert number_of_look_back_candles > 0 and number_of_look_forward_candles.is_integer(), f\"Could not calculate candle count that fits into profit window {lookback_window} for data time frame {time_frame}\"\n",
    "    number_of_look_forward_candles = int(number_of_look_forward_candles)\n",
    "    number_of_look_back_candles = int(number_of_look_back_candles)\n",
    "\n",
    "    # Create entries for past price to be used for signal\n",
    "    # and future price (used for the price correlation)\n",
    "    momentum_offset = to_offset(lookback_window)\n",
    "    profit_offset = to_offset(profit_window)\n",
    "\n",
    "    # No data left after filtering\n",
    "    if len(df.index) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate trading pair age in a column\n",
    "    start = df.index[0]\n",
    "\n",
    "    # Remove first N days of trading history to filter out scam pump and dumps\n",
    "    df = df.loc[df.index > start + min_age].copy()\n",
    "\n",
    "    # No data left after filtering\n",
    "    if len(df) < number_of_look_back_candles:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df[\"age\"] = df.index - start\n",
    "\n",
    "    # Fix missing prices\n",
    "    df[\"open\"] = df[\"open\"].replace(0, np.NaN)\n",
    "\n",
    "    df[\"prev\"] = df[\"open\"].shift(number_of_look_back_candles)\n",
    "    df[\"next\"] = df[\"open\"].shift(-number_of_look_forward_candles)\n",
    "\n",
    "    # What is our predicted price\n",
    "    df[\"price_diff\"] = (df[\"next\"] - df[\"open\"]) / df[\"open\"]  # Get the profit on the final day of profit window\n",
    "\n",
    "    # Calculate signal from the past and price difference to the future\n",
    "    df[\"momentum\"] = (df[\"prev\"] - df[\"open\"]) / df[\"open\"]\n",
    "\n",
    "    #df[\"shifted_close\"] = df[\"volume\"].shift(1).rolling(obv_len).sum()\n",
    "    #shifted_close = df.rolling(obv_len)\n",
    "    #assert shifted_close[\"close\"] is not None\n",
    "    #assert shifted_close[\"volume\"] is not None\n",
    "    #import ipdb ; ipdb.set_trace()\n",
    "    df[\"pvt\"] = pvt(df[\"close\"], df[\"volume\"])\n",
    "    df[\"obv\"] = obv(df[\"close\"], df[\"volume\"])\n",
    "\n",
    "    #df[\"obv\"] = obv(shifted_close[\"close\"], shifted_close[\"volume\"])\n",
    "    #shifted = shifted.iloc[-obv_len:-1]\n",
    "    # df[\"obv\"] = obv(shifted[\"close\"], shifted[\"volume\"])\n",
    "\n",
    "    # Drop any momentum value that seems to be incorrect (more than 99% price movement)\n",
    "    df[\"momentum\"] = np.where(df[\"momentum\"] > 0.99, 0, df[\"momentum\"])\n",
    "    df[\"momentum\"] = np.where(df[\"momentum\"] < -0.99, 0, df[\"momentum\"])\n",
    "    \n",
    "    # df.loc[df[\"bullish\"] & (df[\"momentum\"] >= 0), \"signal\"] = df[\"momentum\"]\n",
    "    # df.loc[df[\"bearish\"] & (df[\"momentum\"] < 0), \"signal\"] = df[\"momentum\"]    \n",
    "    df[\"rolling_cum_volume\"] = df[\"volume\"].rolling(window=long_lookback_window).sum() \n",
    "    df[\"rolling_obv\"] = df[\"obv\"] - df[\"obv\"].shift(periods=number_of_look_back_candles)\n",
    "    df[\"rolling_pvt\"] = df[\"pvt\"] - df[\"pvt\"].shift(periods=number_of_look_back_candles)\n",
    "    # df[\"signal\"] = df[\"rolling_pvt\"].shift(1) / df[\"rolling_cum_volume\"].shift(1)\n",
    "    #df[\"signal\"] = df[\"rolling_obv\"].shift(1) / df[\"rolling_cum_volume\"].shift(1)\n",
    "\n",
    "    if signal_source == \"weighted_ema\":\n",
    "        df = calculate_ema_signal(df)    \n",
    "    elif signal_source == \"momentum\":\n",
    "        df[\"signal\"] = df[\"momentum\"]\n",
    "    else:\n",
    "        raise RuntimeError(f\"Figure out {signal_source}\")\n",
    "    \n",
    "    # On negative signals, we go short.\n",
    "    # On zero signal and lack of data set side to NA\n",
    "    df[\"side\"] = pd.NA\n",
    "    \n",
    "    df.loc[df[\"signal\"] > zero_signal_cut_off, \"side\"] = \"long\"\n",
    "    df.loc[df[\"signal\"] < -zero_signal_cut_off, \"side\"] = \"short\"\n",
    "\n",
    "    # Max and min price wihtin the profit window will determine the profit for longs and shorts respective\n",
    "    df[\"max_future_price\"] = df[\"close\"].rolling(number_of_look_forward_candles).max().shift(-number_of_look_forward_candles) # Get the max profit on the profit window, assuming take profit %\n",
    "    df[\"min_future_price\"] = df[\"close\"].rolling(number_of_look_forward_candles).min().shift(-number_of_look_forward_candles) # Get the max profit on the profit window, assuming take profit %    \n",
    "    \n",
    "    df[\"profit\"] = df[\"price_diff\"]\n",
    "    df[\"profit_max\"] = df[\"profit\"]\n",
    "    df[\"profit_abs\"] = df[\"profit_max\"].abs()\n",
    "    # Calculate profit separately for longs and shorts\n",
    "    # using Pandas Mask\n",
    "    # https://stackoverflow.com/a/33770421/315168\n",
    "    #\n",
    "    # We calculate both profit after X time,\n",
    "    # and also max take profit, assuming\n",
    "    # we could do a perfect trailing stop loss\n",
    "    #\n",
    "    #longs = (df[\"side\"] == \"long\")\n",
    "    #shorts = (df[\"side\"] == \"short\")\n",
    "    #df.loc[longs, \"profit\"] = df[\"price_diff\"]\n",
    "    #df.loc[shorts, \"profit\"] = -df[\"price_diff\"]\n",
    "    #df.loc[longs, \"profit_max\"] = (df[\"max_future_price\"] - df[\"open\"]) / df[\"open\"]  # Get the profit based on max price\n",
    "    #df.loc[shorts, \"profit_max\"] = -(df[\"min_future_price\"] - df[\"open\"]) / df[\"open\"]  # Get the profit based on max price\n",
    "\n",
    "    #df.loc[longs, \"desc\"] = df.agg('{0[ticker]} long'.format, axis=1)\n",
    "    #df.loc[shorts, \"desc\"] = df.agg('{0[ticker]} short'.format, axis=1)\n",
    "\n",
    "    df[\"profit\"] = df[\"profit\"].fillna(0)\n",
    "    df[\"profit_max\"] = df[\"profit_max\"].fillna(0)\n",
    "\n",
    "    # On too low trading volume we zero out signal\n",
    "    candle_volume_threshold = daily_volume_threshold * (time_frame / pd.Timedelta(days=1))\n",
    "    volume_threshold_exceeded = df[\"volume\"] >= candle_volume_threshold\n",
    "    df[\"signal\"] = np.where(volume_threshold_exceeded, df[\"signal\"], np.NaN)\n",
    "    df[\"profit\"] = np.where(volume_threshold_exceeded, df[\"profit\"], np.NaN)\n",
    "    df[\"profit_max\"] = np.where(volume_threshold_exceeded, df[\"profit_max\"], np.NaN)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_signal_vs_price_for_pair(\n",
    "    grouped_candles: DataFrameGroupBy,\n",
    "    pair_id: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate signal vs. profit ratio for an individual pair.\"\"\"\n",
    "    try:\n",
    "        df = grouped_candles.get_group(pair_id).copy()\n",
    "    except KeyError:\n",
    "        # Scam pairs \n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df = calculate_signal_vs_profit(\n",
    "        df,\n",
    "        pair_id,\n",
    "        lookback_window,\n",
    "        profit_window,\n",
    "        time_frame=time_bucket.to_pandas_timedelta(),\n",
    "    )\n",
    "    return df\n",
    "\n",
    "print(\"Calculating signals\")\n",
    "grouped_candles = candles_df.groupby(\"pair_id\")\n",
    "per_pair_data = [calculate_signal_vs_price_for_pair(grouped_candles, pair) for pair in pair_ids]\n",
    "\n",
    "valid_pairs = []\n",
    "zero_signal_pairs = 0\n",
    "for pair_data_df in per_pair_data:\n",
    "    if not pair_data_df.empty and (pair_data_df[\"signal\"].replace(pd.NA, 0).abs() >= zero_signal_cut_off).any():\n",
    "        valid_pairs.append(pair_data_df)        \n",
    "    else:\n",
    "        zero_signal_pairs += 1\n",
    "        \n",
    "\n",
    "print(f\"Pairs with valid signal data {len(valid_pairs):,}\")\n",
    "print(f\"Pairs with zero signal: {zero_signal_pairs:,}\")\n",
    "\n",
    "df = pd.concat(valid_pairs)    \n",
    "\n",
    "# Fix column order for table rendering\n",
    "df.insert(0, 'signal', df.pop('signal'))\n",
    "df.insert(0, 'profit', df.pop('profit'))\n",
    "\n",
    "print(f\"Total signal samples {len(df):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_background_job(sma_short: int, sma_long: iint, profit_window: pd.Timdelta) -> tuple:\n",
    "    # Create signal vs. price analysis for examined pairs and calculate correlation\n",
    "    # Make a copy of DataFrame as it is mutated in-place\n",
    "            \n",
    "    signal_vs_profit = [calculate_signal_vs_price_for_pair(df.copy(), look_back, look_forward) for df in pair_dfs]\n",
    "    \n",
    "    # Calculate linear regression for signal vs. profit \n",
    "    df = pd.concat(signal_vs_profit)\n",
    "    df = df.dropna()\n",
    "    df = df.loc[df[\"profit\"] >= profit_threshold]\n",
    "    longs = df.loc[df[\"side\"] == \"long\"]\n",
    "    shorts = df.loc[df[\"side\"] == \"short\"]\n",
    "\n",
    "    # https://stackoverflow.com/a/54685349/315168\n",
    "    #regression = sm.OLS(df[\"profit_max\"], df[\"signal\"]).fit()\n",
    "    long_regression = sm.OLS(longs[\"profit\"], longs[\"signal\"]).fit()\n",
    "    short_regression = sm.OLS(shorts[\"profit\"], shorts[\"signal\"]).fit()\n",
    "    return look_back, look_forward, long_regression, short_regression\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tradeexecutor.backtest.grid_search import perform_grid_search, prepare_grid_combinations\n",
    "\n",
    "# This is the path where we keep the result files around\n",
    "storage_folder = Path(f\"/tmp/{strategy_path.stem}-grid-search\")\n",
    "\n",
    "parameters = {\n",
    "    \"sma_short\": [1, 2, 4, 8],\n",
    "    \"long\": [8, 16, 24, 32],\n",
    "    \"profit_window\": [2, 4, 8, 16],\n",
    "}\n",
    "\n",
    "combinations = prepare_grid_combinations(parameters, storage_folder, clear_cached_results=True)\n",
    "\n",
    "grid_search_results = perform_grid_search(\n",
    "    python_mod.grid_search_worker,\n",
    "    universe,\n",
    "    combinations,\n",
    "    max_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.grid_search import analyse_grid_search_result\n",
    "from tradeexecutor.analysis.grid_search import visualise_table\n",
    "table = analyse_grid_search_result(grid_search_results)\n",
    "\n",
    "visualise_table(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade-executor-8Oz1GdY1-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
